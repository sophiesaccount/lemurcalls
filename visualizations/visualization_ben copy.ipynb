{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea9684c",
   "metadata": {},
   "source": [
    "## Visualization of Spectograms with Labels and Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710222d",
   "metadata": {},
   "source": [
    "Goals: \n",
    "- first line: spectorgam (well readable with axes describtions)\n",
    "- second line: ground-truth labels: bars from each onset to offset in color of class\n",
    "- third line: ground-truth labels: bars from each onset to offset in color of class\n",
    "\n",
    "maybe use parts of Bens code but also make it efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d59a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers.audio_utils import mel_filter_bank\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import numpy as npS\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "import json\n",
    "import re\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import clear_output, display\n",
    "from matplotlib.patches import Rectangle\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8fec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use WhisperSegFeatureExtractor to generate LogMel Spectorgams (other melscale and norm than librosa)\n",
    "\n",
    "class WhisperSegFeatureExtractor( WhisperFeatureExtractor ):\n",
    "    def __init__(self, sr, spec_time_step, min_frequency = None, max_frequency = None, chunk_length = 30 ):\n",
    "        \n",
    "        hop_length = int( spec_time_step * sr )\n",
    "        if hop_length != spec_time_step * sr:\n",
    "            print(\"Warning: spec_time_step * sr must be an integer. Consider changing the sampling rate sr.\")\n",
    "        \n",
    "        if sr <= 32000:\n",
    "            n_fft = 512\n",
    "        elif sr <= 80000:\n",
    "            n_fft = 1024\n",
    "        elif sr <= 150000:\n",
    "            n_fft = 2048\n",
    "        elif sr <= 300000:\n",
    "            n_fft = 4096\n",
    "        else:\n",
    "            n_fft = 8192\n",
    "            \n",
    "        if min_frequency is None:\n",
    "            min_frequency = 0\n",
    "        if max_frequency is None:\n",
    "            max_frequency = sr // 2\n",
    "            \n",
    "        super().__init__(             \n",
    "            feature_size=80,\n",
    "            sampling_rate=sr,\n",
    "            hop_length=hop_length,\n",
    "            chunk_length = chunk_length,\n",
    "            n_fft=n_fft,\n",
    "            padding_value=0.0,\n",
    "            return_attention_mask=False )\n",
    "            \n",
    "        self.mel_filters = mel_filter_bank(\n",
    "            num_frequency_bins=1 + n_fft // 2,\n",
    "            num_mel_filters=80,\n",
    "            min_frequency=min_frequency,\n",
    "            max_frequency=max_frequency,\n",
    "            sampling_rate=sr,\n",
    "            norm=\"slaney\",\n",
    "            mel_scale=\"slaney\",\n",
    "        )\n",
    "            \n",
    "class SpecViewer:\n",
    "    def __init__( self,  ):\n",
    "        self.colors = [np.array(mcolors.hex2color(color_string)) for color_string in list(mcolors.TABLEAU_COLORS.values()) + list(mcolors.CSS4_COLORS.values())][1:] # Skip the first color since it looks not so good ...\n",
    "        unique_colors = None\n",
    "        for color_arr in self.colors:\n",
    "            if unique_colors is None:\n",
    "                unique_colors = np.asarray([color_arr])\n",
    "            else:\n",
    "                if np.all( unique_colors == color_arr, axis = 1 ).sum() == 0:\n",
    "                    unique_colors = np.concatenate( [unique_colors, color_arr[np.newaxis,:]], axis = 0 )\n",
    "        self.colors = unique_colors[ unique_colors.mean(axis = 1) < 0.8, : ]\n",
    "        \n",
    "        self.cmap = cm.get_cmap(\"magma\")\n",
    "            \n",
    "    \"\"\"\"\n",
    "    The following functions are used for implement an interactive visulization function to see the spectrogram and the label\n",
    "    \"\"\"\n",
    "    def filter_by_category(self, d, category):\n",
    "        \"\"\"Returns a filtered dictionary containing only items in the given category.\"\"\"\n",
    "        mask = np.array(d[\"cluster\"]) == str(category)\n",
    "        return {\n",
    "            \"onset\": np.array(d[\"onset\"])[mask].tolist(),\n",
    "            \"offset\": np.array(d[\"offset\"])[mask].tolist(),\n",
    "            \"cluster\": np.array(d[\"cluster\"])[mask].tolist()\n",
    "        }\n",
    "\n",
    "\n",
    "    def chunk_audio(self, audio, start_time, end_time, sr):\n",
    "        start_idx = int( start_time * sr )\n",
    "        end_idx = int( end_time * sr )\n",
    "        chunked_audio = audio[start_idx:end_idx]\n",
    "        return chunked_audio    \n",
    "\n",
    "    def chunk_label(self, label, start_time, end_time ):\n",
    "        \n",
    "        label_onset_arr = np.array(label[\"onset\"])\n",
    "        label_offset_arr = np.array(label[\"offset\"])\n",
    "        \n",
    "        intersected_indices = np.logical_and( label_onset_arr < end_time, label_offset_arr > start_time )\n",
    "        chunked_label = {\n",
    "                \"onset\": (np.maximum(label_onset_arr[intersected_indices], start_time ) - start_time).tolist(),\n",
    "                \"offset\": (np.minimum(label_offset_arr[intersected_indices], end_time ) - start_time).tolist(),\n",
    "                \"cluster\": [ label[\"cluster\"][idx] for idx in np.argwhere(intersected_indices)[:,0] ]\n",
    "            }\n",
    "        return chunked_label   \n",
    "    \n",
    "    def min_max_norm(self, im, min_value = None, max_value = None ):\n",
    "        if min_value is None:\n",
    "            min_value = im.min()\n",
    "        if max_value is None:\n",
    "            max_value = im.max()\n",
    "        return (im -  min_value ) / max( max_value - min_value, 1e-12 )\n",
    "\n",
    "    def overlap_ratio(self, a_start, a_end, b_start, b_end):\n",
    "        inter_start = max(a_start, b_start)\n",
    "        inter_end = min(a_end, b_end)\n",
    "        inter = max(0, inter_end - inter_start)\n",
    "        union = max(a_end, b_end) - min(a_start, b_start)\n",
    "        return inter / union if union > 0 else 0\n",
    "    \n",
    "    \n",
    "    def get_fp_fn_indices(self, predictions, labels, tolerance=0.1):\n",
    "        # predictions, labels: Dicts mit onset, offset, cluster\n",
    "        # Rückgabewerte: Listen der Indizes von FP und FN\n",
    "        import pandas as pd\n",
    "\n",
    "        pred_df = pd.DataFrame(predictions)\n",
    "        label_df = pd.DataFrame(labels)\n",
    "        matched_pred = set()\n",
    "        matched_label = set()\n",
    "        fp_indices = []\n",
    "        fn_indices = []\n",
    "\n",
    "        for label_idx, label_row in label_df.iterrows():\n",
    "            label_onset = label_row[\"onset\"]\n",
    "            label_offset = label_row[\"offset\"]\n",
    "            label_cluster = label_row[\"cluster\"]\n",
    "\n",
    "            found = False\n",
    "            for pred_idx, pred_row in pred_df.iterrows():\n",
    "                pred_onset = pred_row[\"onset\"]\n",
    "                pred_offset = pred_row[\"offset\"]\n",
    "                pred_cluster = pred_row[\"cluster\"]\n",
    "                intersection = max(0, min(pred_offset, label_offset) - max(pred_onset, label_onset))\n",
    "                union = max(pred_offset, label_offset) - min(pred_onset, label_onset)\n",
    "                overlap_ratio = intersection / union if union > 0 else 0\n",
    "\n",
    "                if overlap_ratio > tolerance:\n",
    "                    found = True\n",
    "                    if pred_cluster == label_cluster:\n",
    "                        matched_pred.add(pred_idx)\n",
    "                        matched_label.add(label_idx)\n",
    "                    else:\n",
    "                        matched_pred.add(pred_idx) # zählt als falsch klassifiziert, nicht FN\n",
    "                        matched_label.add(label_idx)\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                fn_indices.append(label_idx)\n",
    "\n",
    "        for pred_idx in range(len(pred_df)):\n",
    "            if pred_idx not in matched_pred:\n",
    "                fp_indices.append(pred_idx)\n",
    "\n",
    "        return fp_indices, fn_indices\n",
    "    \n",
    "    def plot_spec_and_labels(self, offset, window_size, audio, prediction, label, sr, audio_file_name, feature_extractor, precision_bits , min_spec_value, max_spec_value, xticks_step_size ):\n",
    "        \n",
    "        all_unique_clusters = sorted(list(set( list(label[\"cluster\"]) + list(prediction[\"cluster\"]) )))\n",
    "        cluster_color_mapper = {}\n",
    "        for cluster in all_unique_clusters:\n",
    "            if cluster not in cluster_color_mapper:\n",
    "                cluster_color_mapper[cluster] = self.colors[ len(cluster_color_mapper) % len(self.colors) ]\n",
    "        \n",
    "        patches = [Patch(color=color, label=cluster) for cluster, color in cluster_color_mapper.items()]\n",
    "                \n",
    "        start_time = offset\n",
    "        end_time = start_time + window_size\n",
    "        \n",
    "        audio_chunked = self.chunk_audio( audio, start_time, end_time, sr )\n",
    "        label_chunked = self.chunk_label( label, start_time, end_time )\n",
    "        prediction_chunked = self.chunk_label( prediction, start_time, end_time )\n",
    "        \n",
    "        spec = feature_extractor( audio_chunked, sampling_rate=sr, padding = \"do_not_pad\" )[\"input_features\"][0]\n",
    "                \n",
    "        ## convert spec to colorful (3 channel)\n",
    "        spec_colorful =  self.cmap(self.min_max_norm(spec,min_spec_value, max_spec_value))[:,:,:3]\n",
    "        spec_colorful = np.flipud(spec_colorful) \n",
    "        \n",
    "        spec_time_step = feature_extractor.hop_length / sr\n",
    "        spec_xticks_step_size = int(np.round( xticks_step_size / spec_time_step )) \n",
    "        spec_xticks_values = np.arange(0, spec.shape[1]+1, spec_xticks_step_size )\n",
    "        \n",
    "        # spec_xticks_labels = np.round(spec_xticks_values * spec_time_step + start_time, precision_bits) \n",
    "        xticks_format = \"%%.%df\"%(precision_bits)\n",
    "        spec_xticks_labels = [ xticks_format%(v) for v in spec_xticks_values * spec_time_step + start_time ]\n",
    "        \n",
    "        \n",
    "        spec_labels_image = np.ones( ( spec.shape[1], 3 ), dtype = np.float32 )\n",
    "        for pos in range(len(label_chunked[\"onset\"])):\n",
    "            onset_idx = int(np.round(label_chunked[\"onset\"][pos]/spec_time_step))\n",
    "            offset_idx = int(np.round(label_chunked[\"offset\"][pos]/spec_time_step)) \n",
    "            cluster = label_chunked[\"cluster\"][pos]\n",
    "            \n",
    "            ## Add a gap manually if there are two connected segments that have the same cluster but are segmented into two parts (either by human or by machine)\n",
    "            if pos + 1<len(label_chunked[\"onset\"]) and \\\n",
    "                          offset_idx == int(np.round(label_chunked[\"onset\"][pos+1]/spec_time_step)) and \\\n",
    "                          cluster == label_chunked[\"cluster\"][pos+1]:\n",
    "                offset_idx -= 1\n",
    "            \n",
    "            spec_labels_image[onset_idx:offset_idx,:] = cluster_color_mapper[cluster]\n",
    "        spec_labels_image = np.tile( spec_labels_image[np.newaxis,:,:], [40,1,1] )\n",
    "        \n",
    "        \n",
    "        spec_preds_image = np.ones( (spec.shape[1], 3), dtype = np.float32 )\n",
    "        for pos in range(len(prediction_chunked[\"onset\"])):\n",
    "            onset_idx = int(np.round(prediction_chunked[\"onset\"][pos]/spec_time_step))\n",
    "            offset_idx = int(np.round(prediction_chunked[\"offset\"][pos]/spec_time_step))\n",
    "            cluster = prediction_chunked[\"cluster\"][pos]\n",
    "            \n",
    "            if pos + 1<len(prediction_chunked[\"onset\"]) and \\\n",
    "                            offset_idx == int(np.round(prediction_chunked[\"onset\"][pos+1]/spec_time_step)) and \\\n",
    "                            cluster == prediction_chunked[\"cluster\"][pos+1]:\n",
    "                offset_idx -= 1\n",
    "            \n",
    "            spec_preds_image[onset_idx:offset_idx,:] = cluster_color_mapper[cluster]\n",
    "        spec_preds_image = np.tile( spec_preds_image[np.newaxis,:,:], [40,1,1] )\n",
    "        \n",
    "        \n",
    "        canvas_image = np.ones( ( spec_colorful.shape[0] + 10 + 40 + 10 + 40, spec_labels_image.shape[1], 3 ) )\n",
    "        canvas_image[:spec_colorful.shape[0],:,:] = spec_colorful\n",
    "        canvas_image[spec_colorful.shape[0]+10:spec_colorful.shape[0]+50,:,:] = spec_preds_image \n",
    "        canvas_image[spec_colorful.shape[0]+60:spec_colorful.shape[0]+100,:,:] = spec_labels_image\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 3), constrained_layout=True)\n",
    "        gs = fig.add_gridspec(3, 1, height_ratios=[spec.shape[0], 40, 40], hspace=0.2)\n",
    "\n",
    "\n",
    "        # Spektrogramm\n",
    "        ax_spec = fig.add_subplot(gs[0])\n",
    "        ax_spec.imshow(spec_colorful, aspect='equal', origin='upper') \n",
    "        ax_spec.set_ylabel(\"Frequency (kHz)\")\n",
    "        ax_spec.set_xticks(spec_xticks_values)\n",
    "        ax_spec.set_xticklabels(spec_xticks_labels)\n",
    "        ax_spec.set_xlabel(\"Time (s)\")\n",
    "\n",
    "        # Y-Ticks wie vorher (deine Tick-Logik hier rein!)\n",
    "        num_mel_bins = spec.shape[0]\n",
    "        mel_bin_freqs = np.linspace(sr / 2, 0, num_mel_bins)\n",
    "        tick_freqs_khz = np.arange(0, int(sr / 2 / 1000) + 1, 1)\n",
    "        tick_positions = [np.argmin(np.abs(mel_bin_freqs - f * 1000)) for f in tick_freqs_khz]\n",
    "        tick_labels = [f\"{f}\" for f in tick_freqs_khz]\n",
    "        ax_spec.set_yticks(tick_positions)\n",
    "        ax_spec.set_yticklabels(tick_labels)\n",
    "\n",
    "        # Prediction-Balken\n",
    "        ax_pred = fig.add_subplot(gs[1])\n",
    "        ax_pred.imshow(spec_preds_image, aspect='equal', origin='upper')\n",
    "        ax_pred.set_yticks([])\n",
    "        ax_pred.set_xticks([])\n",
    "        ax_pred.spines[['top', 'bottom', 'right', 'left']].set_visible(False)\n",
    "\n",
    "        # Label-Balken\n",
    "        ax_label = fig.add_subplot(gs[2])\n",
    "        ax_label.imshow(spec_labels_image, aspect='equal', origin='upper')\n",
    "        ax_label.set_xticks([]) \n",
    "        ax_label.set_yticks([])\n",
    "        ax_label.spines[['top', 'bottom', 'right', 'left']].set_visible(False)\n",
    "        \n",
    "        # Legende oben rechts\n",
    "        patches = [Patch(color=color, label=cluster) for cluster, color in cluster_color_mapper.items()]\n",
    "        patches.append(Patch(facecolor='none', edgecolor='red', linewidth=2, label='False Positive'))\n",
    "        patches.append(Patch(facecolor='none', edgecolor='blue', linewidth=2, label='False Negative'))\n",
    "        plt.legend(handles=patches, loc=\"upper right\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "        fp_indices, fn_indices = self.get_fp_fn_indices(prediction_chunked, label_chunked)\n",
    "        # Für False Positives: auf ax_pred (Prediction-Balken)\n",
    "        for idx in fp_indices:\n",
    "            onset = prediction_chunked[\"onset\"][idx]\n",
    "            offset = prediction_chunked[\"offset\"][idx]\n",
    "            onset_idx = int(np.round(onset / spec_time_step))\n",
    "            offset_idx = int(np.round(offset / spec_time_step))\n",
    "            rect = Rectangle((onset_idx, -1), offset_idx - onset_idx, spec_preds_image.shape[0],\n",
    "                            linewidth=2, edgecolor='red', facecolor='none')\n",
    "            ax_pred.add_patch(rect)\n",
    "\n",
    "        # Für False Negatives: auf ax_label (Label-Balken)\n",
    "        for idx in fn_indices:\n",
    "            onset = label_chunked[\"onset\"][idx]\n",
    "            offset = label_chunked[\"offset\"][idx]\n",
    "            onset_idx = int(np.round(onset / spec_time_step))\n",
    "            offset_idx = int(np.round(offset / spec_time_step))\n",
    "            rect = Rectangle((onset_idx, -1), offset_idx - onset_idx, spec_labels_image.shape[0],\n",
    "                            linewidth=2, edgecolor='blue', facecolor='none')\n",
    "            ax_label.add_patch(rect)\n",
    "\n",
    "        audio_chunked = self.chunk_audio(audio, offset, offset+window_size, sr)\n",
    "        display(Audio(audio_chunked, rate=sr))\n",
    "                \n",
    "    def visualize( self, audio, sr, prediction = None, label = None, min_frequency = None, max_frequency = None, precision_bits = 3, audio_file_name = \"\", window_size = 5.0, xticks_step_size = 0.5, spec_width = 1000):\n",
    "    \n",
    "        feature_extractor = WhisperSegFeatureExtractor( sr, window_size / spec_width, min_frequency, max_frequency )\n",
    "        \n",
    "        \n",
    "        whole_spec = feature_extractor( audio, sampling_rate=sr, padding = \"do_not_pad\" )[\"input_features\"][0]\n",
    "        min_spec_value = None  # np.percentile( whole_spec, 0.02)\n",
    "        max_spec_value = None  # np.percentile( whole_spec, 99.98)\n",
    "        \n",
    "        if isinstance( label, pd.DataFrame ):\n",
    "            label_dict = label.to_dict(\"list\")\n",
    "            \n",
    "        if isinstance( prediction, pd.DataFrame ):\n",
    "            prediction = prediction.to_dict(\"list\")\n",
    "        \n",
    "        if label is None:\n",
    "            label = {\"onset\":[], \"offset\":[], \"cluster\":[] }\n",
    "        if prediction is None:\n",
    "            prediction = {\"onset\":[], \"offset\":[], \"cluster\":[] }\n",
    "                \n",
    "        label[\"cluster\"] = list(map(str, label[\"cluster\"]))\n",
    "        prediction[\"cluster\"] = list(map(str, prediction[\"cluster\"]))\n",
    "        \n",
    "        return interact(self.plot_spec_and_labels, \n",
    "                    offset=(0, max(0, len(audio)/sr - window_size ), window_size / 20 ), \n",
    "                    window_size = fixed(window_size), \n",
    "                    audio = fixed(audio), \n",
    "                    prediction = fixed(prediction),\n",
    "                    label = fixed(label), \n",
    "                    sr = fixed(sr), \n",
    "                    audio_file_name = fixed(audio_file_name),\n",
    "                    feature_extractor = fixed(feature_extractor),\n",
    "                    precision_bits = fixed(precision_bits),\n",
    "                    min_spec_value = fixed(min_spec_value),\n",
    "                    max_spec_value = fixed(max_spec_value),\n",
    "                    xticks_step_size = fixed(xticks_step_size)\n",
    "                        )\n",
    "    def _evaluate_performance_single(self, label, prediction, tolerance=0.1\n",
    "\n",
    "\n",
    "\n",
    "    ):\n",
    "        import pandas as pd\n",
    "\n",
    "        label = {\"onset\": [], \"offset\": [], \"cluster\": []} if label is None else label\n",
    "        prediction = {\"onset\": [], \"offset\": [], \"cluster\": []} if prediction is None else prediction\n",
    "        label[\"cluster\"] = list(map(str, label[\"cluster\"]))\n",
    "        prediction[\"cluster\"] = list(map(str, prediction[\"cluster\"]))\n",
    "\n",
    "        label_df = pd.DataFrame(label)\n",
    "        pred_df = pd.DataFrame(prediction)\n",
    "        matched_pred = set()\n",
    "        matched_label = set()\n",
    "        false_class = 0\n",
    "\n",
    "        for label_idx, label_row in label_df.iterrows():\n",
    "            label_onset = label_row[\"onset\"]\n",
    "            label_offset = label_row[\"offset\"]\n",
    "            label_cluster = label_row[\"cluster\"]\n",
    "\n",
    "            for pred_idx, pred_row in pred_df.iterrows():\n",
    "                if pred_idx in matched_pred:\n",
    "                    continue\n",
    "                pred_onset = pred_row[\"onset\"]\n",
    "                pred_offset = pred_row[\"offset\"]\n",
    "                pred_cluster = pred_row[\"cluster\"]\n",
    "\n",
    "                intersection = max(0, min(pred_offset, label_offset) - max(pred_onset, label_onset))\n",
    "                union = max(pred_offset, label_offset) - min(pred_onset, label_onset)\n",
    "                overlap_ratio = intersection / union if union > 0 else 0\n",
    "\n",
    "                if overlap_ratio > tolerance:\n",
    "                    if pred_cluster == label_cluster:\n",
    "                        matched_pred.add(pred_idx)\n",
    "                        matched_label.add(label_idx)\n",
    "                        break\n",
    "                    else:\n",
    "                        false_class += 1\n",
    "                        matched_pred.add(pred_idx)\n",
    "                        matched_label.add(label_idx)\n",
    "                        break\n",
    "\n",
    "        tp = len(matched_label) - false_class\n",
    "        fp = len(pred_df) - len(matched_pred)\n",
    "        fn = len(label_df) - len(matched_label)\n",
    "        fc = false_class\n",
    "\n",
    "        print(f\"True Positives (TP): {tp}\")\n",
    "        print(f\"False Class (FC):    {fc}  (timed right, wrong label)\")\n",
    "        print(f\"False Positives (FP): {fp}\")\n",
    "        print(f\"False Negatives (FN): {fn}\\n\")\n",
    "\n",
    "        denom_precision = tp + fp + fc\n",
    "        denom_recall = tp + fn + fc\n",
    "\n",
    "        precision = tp / denom_precision if denom_precision > 0 else 0\n",
    "        recall = tp / denom_recall if denom_recall > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        print(f\"Segment-wise Precision: {precision:.4f}\")\n",
    "        print(f\"Segment-wise Recall:    {recall:.4f}\")\n",
    "        print(f\"Segment-wise F1 Score:  {f1:.4f}\")\n",
    "\n",
    "\n",
    "    def evaluate_performance_overall(self, prediction=None, label=None, tolerance=0.1):\n",
    "        import pandas as pd\n",
    "\n",
    "        label = {\"onset\": [], \"offset\": [], \"cluster\": []} if label is None else label\n",
    "        prediction = {\"onset\": [], \"offset\": [], \"cluster\": []} if prediction is None else prediction\n",
    "        label[\"cluster\"] = list(map(str, label[\"cluster\"]))\n",
    "        prediction[\"cluster\"] = list(map(str, prediction[\"cluster\"]))\n",
    "\n",
    "        self.pred_df = pd.DataFrame(prediction)\n",
    "        self.label_df = pd.DataFrame(label)\n",
    "\n",
    "        if self.pred_df.empty or self.label_df.empty:\n",
    "            print(\"Keine Vorhersagen oder Labels vorhanden.\")\n",
    "            return\n",
    "\n",
    "        pred_df = self.pred_df.copy()\n",
    "        label_df = self.label_df.copy()\n",
    "\n",
    "        # categories can be [\"vocal\", \"target\"] or anything that matches your use case\n",
    "        categories = [\"vocal\", \"target\"]\n",
    "\n",
    "        for cat in categories:\n",
    "            label_cat = self.filter_by_category(label, cat)\n",
    "            prediction_cat = self.filter_by_category(prediction, cat)\n",
    "            print(f\"\\n=== Evaluation for category: {cat.upper()} ===\")\n",
    "            self._evaluate_performance_single(label_cat, prediction_cat, tolerance)  # see below\n",
    "\n",
    "        matched_pred = set()\n",
    "        matched_label = set()\n",
    "        false_class = 0  # Zähler für zeitlich passende, aber falsch klassifizierte Vorhersagen\n",
    "\n",
    "        # Suche True Positives und False Class\n",
    "        for label_idx, label_row in label_df.iterrows():\n",
    "            label_onset = label_row[\"onset\"]\n",
    "            label_offset = label_row[\"offset\"]\n",
    "            label_cluster = label_row[\"cluster\"]\n",
    "\n",
    "            for pred_idx, pred_row in pred_df.iterrows():\n",
    "                if pred_idx in matched_pred:\n",
    "                    continue  # Diese Vorhersage wurde schon gematcht\n",
    "\n",
    "                pred_onset = pred_row[\"onset\"]\n",
    "                pred_offset = pred_row[\"offset\"]\n",
    "                pred_cluster = pred_row[\"cluster\"]\n",
    "\n",
    "                intersection = max(0, min(pred_offset, label_offset) - max(pred_onset, label_onset))\n",
    "                union = max(pred_offset, label_offset) - min(pred_onset, label_onset)\n",
    "                overlap_ratio = intersection / union if union > 0 else 0\n",
    "\n",
    "                if overlap_ratio > tolerance:\n",
    "                    if pred_cluster == label_cluster:\n",
    "                        matched_pred.add(pred_idx)\n",
    "                        matched_label.add(label_idx)\n",
    "                        break  # Gültiges Match gefunden\n",
    "                    else:\n",
    "                        false_class += 1\n",
    "                        matched_pred.add(pred_idx)\n",
    "                        matched_label.add(label_idx)\n",
    "                        break  # Auch als Match gezählt, aber mit falscher Klasse\n",
    "\n",
    "        tp = len(matched_label) - false_class\n",
    "        fp = len(pred_df) - len(matched_pred)\n",
    "        fn = len(label_df) - len(matched_label)\n",
    "        fc = false_class\n",
    "\n",
    "        print(\"\\n--- Gesamtauswertung über alle Zeitbereiche ---\")\n",
    "        print(f\"True Positives (TP): {tp}\")\n",
    "        print(f\"False Class (FC):    {fc}  (zeitlich korrekt, aber falsches Label)\")\n",
    "        print(f\"False Positives (FP): {fp}\")\n",
    "        print(f\"False Negatives (FN): {fn}\\n\")\n",
    "\n",
    "        # Präzision, Recall, F1 berechnen (unter Berücksichtigung von False Class)\n",
    "        denom_precision = tp + fp + fc\n",
    "        denom_recall = tp + fn + fc\n",
    "\n",
    "        precision = tp / denom_precision if denom_precision > 0 else 0\n",
    "        recall = tp / denom_recall if denom_recall > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        print(f\"Segment-wise Precision: {precision:.4f}\")\n",
    "        print(f\"Segment-wise Recall:    {recall:.4f}\")\n",
    "        print(f\"Segment-wise F1 Score:  {f1:.4f}\")\n",
    "\n",
    "\n",
    "    \n",
    "def slice_audio_and_label( audio, label, sr, start_time, end_time ):\n",
    "    sliced_audio = audio[ int( start_time * sr ):int( end_time * sr ) ]\n",
    "    duration = len(sliced_audio) / sr\n",
    "    ## get the actual ending time\n",
    "    end_time = start_time + duration\n",
    "    \n",
    "    onsets = np.array( label[\"onset\"] )\n",
    "    offsets = np.array( label[\"offset\"] )\n",
    "    clusters = list(label[\"cluster\"])\n",
    "    \n",
    "    target_indices = np.argwhere( np.logical_and( onsets < end_time, offsets > start_time ) )[:,0]\n",
    "    \n",
    "    sliced_onsets = [ max( 0, onsets[idx] - start_time ) for idx in target_indices ]\n",
    "    sliced_offsets = [ min( offsets[idx] - start_time, end_time - start_time ) for idx in target_indices ]    \n",
    "    sliced_clusters = [ clusters[idx] for idx in target_indices ]\n",
    "    \n",
    "    sliced_label = {\n",
    "        \"onset\":sliced_onsets,\n",
    "        \"offset\":sliced_offsets,\n",
    "        \"cluster\":sliced_clusters,\n",
    "    }\n",
    "    \n",
    "    if isinstance( label, pd.DataFrame ):\n",
    "        sliced_label = pd.DataFrame( sliced_label )\n",
    "    \n",
    "    return sliced_audio, sliced_label\n",
    "\n",
    "\n",
    "def remove_silent_sections(audio, labels, predictions, sr, silence_threshold=None):\n",
    "    if silence_threshold is None:\n",
    "        return audio, labels, predictions\n",
    "\n",
    "    all_onsets = labels[\"onset\"] + predictions[\"onset\"]\n",
    "    all_offsets = labels[\"offset\"] + predictions[\"offset\"]\n",
    "    \n",
    "    if not all_onsets or not all_offsets:\n",
    "        return audio, labels, predictions  # Keine Events vorhanden\n",
    "\n",
    "    intervals = sorted(zip(all_onsets, all_offsets), key=lambda x: x[0])\n",
    "    merged_intervals = []\n",
    "\n",
    "    for start, end in intervals:\n",
    "        if not merged_intervals:\n",
    "            merged_intervals.append([start, end])\n",
    "        else:\n",
    "            last = merged_intervals[-1]\n",
    "            if start <= last[1]:\n",
    "                last[1] = max(last[1], end)\n",
    "            else:\n",
    "                merged_intervals.append([start, end])\n",
    "\n",
    "    new_audio = []\n",
    "    new_labels = {\"onset\": [], \"offset\": [], \"cluster\": []}\n",
    "    new_predictions = {\"onset\": [], \"offset\": [], \"cluster\": []}\n",
    "    current_time = 0.0\n",
    "    last_end = 0.0\n",
    "\n",
    "    for i, (start, end) in enumerate(merged_intervals):\n",
    "        gap = start - last_end\n",
    "        if silence_threshold is not None and gap > silence_threshold:\n",
    "            current_time += gap\n",
    "        sliced_audio, sliced_label = slice_audio_and_label(audio, labels, sr, start, end)\n",
    "        _, sliced_pred = slice_audio_and_label(audio, predictions, sr, start, end)\n",
    "\n",
    "        new_audio.append(sliced_audio)\n",
    "\n",
    "        new_labels[\"onset\"] += [o + current_time for o in sliced_label[\"onset\"]]\n",
    "        new_labels[\"offset\"] += [o + current_time for o in sliced_label[\"offset\"]]\n",
    "        new_labels[\"cluster\"] += sliced_label[\"cluster\"]\n",
    "\n",
    "        new_predictions[\"onset\"] += [o + current_time for o in sliced_pred[\"onset\"]]\n",
    "        new_predictions[\"offset\"] += [o + current_time for o in sliced_pred[\"offset\"]]\n",
    "        new_predictions[\"cluster\"] += sliced_pred[\"cluster\"]\n",
    "\n",
    "        current_time += len(sliced_audio) / sr\n",
    "        last_end = end\n",
    "\n",
    "    new_audio = np.concatenate(new_audio) if new_audio else np.array([], dtype=np.float32)\n",
    "    return new_audio, new_labels, new_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5605ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sophi\\AppData\\Local\\Temp\\ipykernel_10356\\3921853444.py:57: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  self.cmap = cm.get_cmap(\"magma\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation for category: VOCAL ===\n",
      "True Positives (TP): 122\n",
      "False Class (FC):    0  (timed right, wrong label)\n",
      "False Positives (FP): 119\n",
      "False Negatives (FN): 59\n",
      "\n",
      "Segment-wise Precision: 0.5062\n",
      "Segment-wise Recall:    0.6740\n",
      "Segment-wise F1 Score:  0.5782\n",
      "\n",
      "=== Evaluation for category: TARGET ===\n",
      "True Positives (TP): 0\n",
      "False Class (FC):    0  (timed right, wrong label)\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 0\n",
      "\n",
      "Segment-wise Precision: 0.0000\n",
      "Segment-wise Recall:    0.0000\n",
      "Segment-wise F1 Score:  0.0000\n",
      "\n",
      "--- Gesamtauswertung über alle Zeitbereiche ---\n",
      "True Positives (TP): 122\n",
      "False Class (FC):    0  (zeitlich korrekt, aber falsches Label)\n",
      "False Positives (FP): 119\n",
      "False Negatives (FN): 59\n",
      "\n",
      "Segment-wise Precision: 0.5062\n",
      "Segment-wise Recall:    0.6740\n",
      "Segment-wise F1 Score:  0.5782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d59200cad9410288054b5ff688e7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1076.0, description='offset', max=2155.6073125, step=2.0), Output()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Dateien laden ---\n",
    "#wav_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first.wav\"\n",
    "#json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first.json\"\n",
    "#pred_json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first_pred.json\"\n",
    "\n",
    "wav_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first.wav\"\n",
    "#json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first.json\"\n",
    "#pred_json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first_pred.json\"\n",
    "#pred_json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\train.py, only finetune, 5 epochs, on lemur_2call_data, test\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first.jsonr\"\n",
    "#pred_json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\models\\16.6. 15 epochs, af_without_cp_newscheduler, only finetuning, lemur_data_2call\\Neuer Ordner\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first.jsonr\"\n",
    "#pred_json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\models\\16.6. 15 epochs, af_without_cp_newscheduler, only finetuning, lemur_data_2call\\pred_empty.jsonr\"\n",
    "#pred_json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\18.6\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first.jsonr\"\n",
    "# Audio laden\n",
    "\n",
    "json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\Raven\\labels_yesno.json\"\n",
    "pred_json_path = r\"C:\\Users\\sophi\\Documents\\Masterarbeit\\Results\\pred\\(2019_03_15-12_02_11)_CSWMUW240241_0000_first_pred.json\"\n",
    "\n",
    "audio, sr = librosa.load(wav_path, sr=None)\n",
    "\n",
    "# Labels aus JSON laden\n",
    "with open(json_path, \"r\") as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "# Prüfen ob alle nötigen Keys existieren\n",
    "assert all(k in labels for k in [\"onset\", \"offset\", \"cluster\"]), \"Labels JSON muss 'onset', 'offset', 'cluster' enthalten.\"\n",
    "\n",
    "# Optional: Cluster als Strings sicherstellen\n",
    "labels[\"cluster\"] = list(map(str, labels[\"cluster\"]))\n",
    "\n",
    "# Predictions aus JSON laden\n",
    "with open(pred_json_path, \"r\") as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "# Prüfen ob alle nötigen Keys existieren\n",
    "assert all(k in predictions for k in [\"onset\", \"offset\", \"cluster\"]), \"Predictions JSON muss 'onset', 'offset', 'cluster' enthalten.\"\n",
    "\n",
    "# Optional: Cluster als Strings sicherstellen\n",
    "predictions[\"cluster\"] = list(map(str, predictions[\"cluster\"]))\n",
    "\n",
    "# --- Stille (>3s) entfernen ---\n",
    "audio_cleaned, labels_cleaned, predictions_cleaned = remove_silent_sections(\n",
    "    audio, labels, predictions, sr, silence_threshold=None\n",
    ")\n",
    "\n",
    "# --- Spektrogramm und Annotationen visualisieren ---\n",
    "viewer = SpecViewer()\n",
    "viewer.evaluate_performance_overall(label=labels_cleaned,\n",
    "    prediction=predictions_cleaned)\n",
    "\n",
    "# Interaktive Visualisierung starten\n",
    "widget = viewer.visualize(\n",
    "    audio=audio_cleaned,\n",
    "    sr=sr,\n",
    "    label=labels,\n",
    "    prediction=predictions_cleaned,\n",
    "    audio_file_name=wav_path,\n",
    "    window_size=40.0,      # Zeitfenstergröße in Sekunden\n",
    "    xticks_step_size=5  # Schrittweite der x-Achsen-Beschriftung in Sekunden\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab749b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bafa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
