{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to use the WhisperSeg Model - Step by Step Guide\n",
        "\n",
        "This notebook runs a trained WhisperSeg model on your audio files and saves the detected calls as `.json` files. Optionally, results can be converted to Raven selection tables.\n",
        "\n",
        "**Always run the cells in order from top to bottom!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Install Dependencies\n",
        "\n",
        "You only need to run this cell the first time running the notebook (it might take some time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install numpy scipy torch transformers huggingface_hub ctranslate2 librosa pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "from utils import infer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Set Paths and Parameters\n",
        "\n",
        "Before running: place your `.wav` files in the `audios/` folder next to this notebook.\n",
        "\n",
        "You also need a **model checkpoint folder** (CT2 format). Two options:\n",
        "- `final_checkpoint_20251116_163404_ct2` -- detects only **high quality** calls (default)\n",
        "- `final_checkpoint_20251113_145510_ct2` -- detects **all quality** classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "PATH = os.getcwd()\n",
        "\n",
        "# --- Paths (adjust if needed) ---\n",
        "DATA_DIR = os.path.join(PATH, \"audios\")\n",
        "MODEL_PATH = os.path.join(PATH, \"final_checkpoint_20251116_163404_ct2\")\n",
        "OUTPUT_DIR = os.path.join(PATH, \"jsons\")\n",
        "\n",
        "# To detect ALL quality classes instead, uncomment the line below:\n",
        "# MODEL_PATH = os.path.join(PATH, \"final_checkpoint_20251113_145510_ct2\")\n",
        "\n",
        "# --- Inference parameters ---\n",
        "MIN_FREQUENCY = 0         # minimum frequency for spectrogram (Hz)\n",
        "SPEC_TIME_STEP = 0.0025   # time step for spectrogram (seconds)\n",
        "MIN_SEGMENT_LENGTH = 0.0195  # minimum segment length (seconds)\n",
        "EPS = 0.02                # DBSCAN epsilon for clustering\n",
        "NUM_TRIALS = 3            # number of segmentation trials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Verify Paths\n",
        "\n",
        "Run this cell to check that all required paths exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_ok = True\n",
        "\n",
        "print(\"Model:\", MODEL_PATH)\n",
        "if os.path.isdir(MODEL_PATH):\n",
        "    contents = os.listdir(MODEL_PATH)\n",
        "    has_model = any(f.endswith(\".bin\") for f in contents)\n",
        "    print(f\"  OK (directory with {len(contents)} files, model.bin: {'found' if has_model else 'MISSING'})\")\n",
        "    if not has_model:\n",
        "        all_ok = False\n",
        "else:\n",
        "    print(\"  MISSING -- please provide the CT2 model checkpoint folder\")\n",
        "    all_ok = False\n",
        "\n",
        "print(\"Audio folder:\", DATA_DIR)\n",
        "if os.path.isdir(DATA_DIR):\n",
        "    wav_files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".wav\")]\n",
        "    print(f\"  OK ({len(wav_files)} WAV file(s) found)\")\n",
        "    if not wav_files:\n",
        "        print(\"  WARNING: no .wav files found in audios/\")\n",
        "        all_ok = False\n",
        "else:\n",
        "    print(\"  MISSING -- create an 'audios' folder and place your .wav files there\")\n",
        "    all_ok = False\n",
        "\n",
        "print()\n",
        "if all_ok:\n",
        "    print(\"Everything looks good! Proceed to Step 5.\")\n",
        "else:\n",
        "    print(\"Please fix the issues above before running inference.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Run Inference\n",
        "\n",
        "This will process all `.wav` files in `audios/` and save predictions as `.json` files in `jsons/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = infer(\n",
        "    data_dir=DATA_DIR,\n",
        "    model_path=MODEL_PATH,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    min_frequency=MIN_FREQUENCY,\n",
        "    spec_time_step=SPEC_TIME_STEP,\n",
        "    min_segment_length=MIN_SEGMENT_LENGTH,\n",
        "    eps=EPS,\n",
        "    num_trials=NUM_TRIALS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Results Summary\n",
        "\n",
        "Overview of the detected calls per file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total = 0\n",
        "for filename, preds in results.items():\n",
        "    n = len(preds.get(\"onset\", []))\n",
        "    total += n\n",
        "    clusters = {}\n",
        "    for c in preds.get(\"cluster\", []):\n",
        "        clusters[c] = clusters.get(c, 0) + 1\n",
        "    cluster_str = \", \".join(f\"{k}: {v}\" for k, v in sorted(clusters.items()))\n",
        "    print(f\"  {filename}: {n} predictions ({cluster_str})\")\n",
        "\n",
        "print(f\"\\nTotal: {total} predictions across {len(results)} file(s)\")\n",
        "print(f\"Results saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Convert to Raven Selection Tables (Optional)\n",
        "\n",
        "To visualize the results in Raven, convert the `.json` files to `.txt` selection tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from json_to_raven import process_folder\n",
        "\n",
        "JSON_DIR = os.path.join(PATH, \"jsons\")\n",
        "RAVEN_DIR = os.path.join(PATH, \"raven\")\n",
        "\n",
        "process_folder(JSON_DIR, RAVEN_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `.txt` selection tables can now be found in the `raven/` folder. Open them in Raven Pro alongside the corresponding audio files to visualize the detected calls."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
