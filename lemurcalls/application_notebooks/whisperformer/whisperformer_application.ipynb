{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instructions on how to use final WhisperFormer Model - A Step by Step Guide\n",
        "\n",
        "Always run the cells in the correct order!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Install Dependencies\n",
        "\n",
        "You only need to run this cell the first time (it might take some time)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install numpy scipy torch transformers librosa pandas matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import logging\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from utils import infer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Set Paths and Parameters\n",
        "\n",
        "**Required folder structure:**\n",
        "```\n",
        "whisperformer/\n",
        "├── whisperformer_application.ipynb   (this notebook)\n",
        "├── utils.py\n",
        "├── model.py\n",
        "├── json_to_raven.py\n",
        "├── audios/                           (place your .wav files here)\n",
        "├── whisper_config/                   (Whisper config directory, contains config.json etc.)\n",
        "└── checkpoint.pth                    (your trained WhisperFormer checkpoint)\n",
        "```\n",
        "\n",
        "**Important:** The `whisper_config` folder must contain the Whisper model config files (at minimum `config.json`). You can find these in the `whisper_models/whisper_base` or `whisper_models/whisper_large` directory of the main repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "PATH = os.getcwd()\n",
        "\n",
        "DATA_DIR = os.path.join(PATH, \"audios\")\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(PATH, \"checkpoint.pth\")\n",
        "\n",
        "WHISPER_CONFIG_PATH = os.path.join(PATH, \"whisper_config\")\n",
        "\n",
        "OUTPUT_DIR = os.path.join(PATH, \"jsons\")\n",
        "\n",
        "THRESHOLD = 0.35\n",
        "IOU_THRESHOLD = 0.4\n",
        "TOTAL_SPEC_COLUMNS = 3000\n",
        "BATCH_SIZE = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Verify Paths\n",
        "\n",
        "Run this cell to check that all required paths exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"CHECKPOINT_PATH:\", CHECKPOINT_PATH)\n",
        "print(\"  Exists:\", os.path.exists(CHECKPOINT_PATH))\n",
        "\n",
        "print(\"WHISPER_CONFIG_PATH:\", WHISPER_CONFIG_PATH)\n",
        "print(\"  Exists:\", os.path.exists(WHISPER_CONFIG_PATH))\n",
        "if os.path.isdir(WHISPER_CONFIG_PATH):\n",
        "    print(\"  Contents:\", os.listdir(WHISPER_CONFIG_PATH))\n",
        "\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"  Exists:\", os.path.exists(DATA_DIR))\n",
        "if os.path.isdir(DATA_DIR):\n",
        "    wav_files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".wav\")]\n",
        "    print(f\"  WAV files found: {len(wav_files)}\")\n",
        "\n",
        "print(\"Device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Run Inference\n",
        "\n",
        "This will process all `.wav` files in `audios/` and save predictions as `.json` files in `jsons/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "infer(\n",
        "    data_dir=DATA_DIR,\n",
        "    checkpoint_path=CHECKPOINT_PATH,\n",
        "    whisper_config_path=WHISPER_CONFIG_PATH,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    threshold=THRESHOLD,\n",
        "    iou_threshold=IOU_THRESHOLD,\n",
        "    total_spec_columns=TOTAL_SPEC_COLUMNS,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you should be able to see the predictions as `.json` files in the `jsons` folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Convert to Raven Selection Tables (Optional)\n",
        "\n",
        "To visualize the results in Raven, convert the `.json` files to `.txt` selection tables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from json_to_raven import process_folder\n",
        "\n",
        "JSON_DIR = os.path.join(PATH, \"jsons\")\n",
        "RAVEN_DIR = os.path.join(PATH, \"raven\")\n",
        "\n",
        "process_folder(JSON_DIR, RAVEN_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `.txt` files of your results can now be found in the `raven` folder. You can open them directly in Raven Pro alongside the corresponding audio files."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}